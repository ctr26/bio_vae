{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977feac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "# These libraries are crucial for data processing, model training, and logging.\n",
    "import fsspec\n",
    "from torchdata.datapipes.iter import IterableWrapper\n",
    "from PIL import Image\n",
    "import io\n",
    "from joblib import Memory\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from bioimage_embed.lightning.dataloader import DataModule2\n",
    "import submitit\n",
    "import bioimage_embed\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "import os\n",
    "from hydra.utils import instantiate\n",
    "import bioimage_embed.config as config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ad5f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup joblib memory caching\n",
    "# This allows for caching results of functions to avoid reprocessing the same data.\n",
    "memory = Memory(location=\".\", verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10e745a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the number of GPUs per node and the number of nodes for distributed training.\n",
    "NUM_GPUS_PER_NODE = 1\n",
    "NUM_NODES = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0b2117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define FTP host, root directory, and dataset information\n",
    "# We will download images from an FTP server to use in training our model.\n",
    "# The 'spec' dictionary holds information required to access the FTP server and the dataset location.\n",
    "\n",
    "fsspec_local = {\"protocol\": \"file\", \"root\": \"\"}\n",
    "\n",
    "fsspec_ftp = {\n",
    "    \"protocol\": \"ftp\",\n",
    "    \"host\": \"ftp.ebi.ac.uk\",\n",
    "    \"anon\": True,\n",
    "    \"mode\": \"rb\",\n",
    "    \"filecache\": {\"cache_storage\": \"/tmp/idr\"},\n",
    "    \"root\": \"pub/databases/IDR/idr0093-mueller-perturbation\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a60ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the list of files matching the glob pattern\n",
    "# This function uses joblib's memory caching to avoid re-fetching the file list.\n",
    "@memory.cache\n",
    "def get_file_list(glob_str, fs):\n",
    "    return fs.glob(glob_str, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596414ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read a file from the FTP server\n",
    "# This function reads the file and attempts to open it as an image.\n",
    "def read(x):\n",
    "    try:\n",
    "        # Attempt to open the image file and read its contents.\n",
    "        print(x[0])\n",
    "        stream = x[1].read()\n",
    "        return read_image(stream)\n",
    "    except Exception:\n",
    "        # If an error occurs (e.g., the file is not found), return None.\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f5428",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert the binary stream into a PIL Image object\n",
    "# This ensures the image is opened correctly and converted to RGB format.\n",
    "def read_image(x):\n",
    "    return Image.open(io.BytesIO(x)).convert(\"RGB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1832a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if the image is valid\n",
    "# This function checks whether the image file is not None, indicating it was successfully read.\n",
    "def is_valid_image(x):\n",
    "    return x is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b70bcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add a label to the image\n",
    "# For this example, we are just adding a label of 0 to each image.\n",
    "def add_label(x):\n",
    "    return x, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbccafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main training function\n",
    "def train(spec, num_gpus_per_node=1, num_nodes=1):\n",
    "    # Setup fsspec filesystem for FTP access\n",
    "    fs = fsspec.filesystem(**spec)\n",
    "\n",
    "    # Define a glob pattern to match .tif and .tiff files in the dataset directory.\n",
    "    glob_str = spec[\"root\"] + \"/**/*.tif*\"\n",
    "\n",
    "    # Get the list of files to process using the glob pattern\n",
    "    files = get_file_list(glob_str, fs)\n",
    "\n",
    "    # Instantiate the data transformation pipeline from the configuration\n",
    "    transform = instantiate(config.Transform())\n",
    "\n",
    "    # Create the data pipeline\n",
    "    datapipe = (\n",
    "        IterableWrapper(files)  # Wrap the file list in an iterable\n",
    "        .open_files_by_fsspec(**spec)  # Open the files using fsspec\n",
    "        .map(read)  # Read the files from the FTP server\n",
    "        .filter(filter_fn=is_valid_image)  # Filter out invalid images\n",
    "        .map(transform)  # Apply transformations to the images\n",
    "        .map(add_label)  # Add labels to the images\n",
    "        .set_length(len(files))  # Set the length of the data pipeline\n",
    "    )\n",
    "\n",
    "    # Print the first item from the pipeline to check if it's working correctly\n",
    "    a = next(iter(datapipe))\n",
    "    print(a)\n",
    "\n",
    "    # Model training parameters\n",
    "    params = {\n",
    "        \"model\": \"resnet50_vqvae\",\n",
    "        \"opt\": \"lamb\",\n",
    "        \"latent_dim\": 224**2 // 4,\n",
    "        \"max_epochs\": 1000,\n",
    "        \"max_steps\": -1,\n",
    "        \"weight_decay\": 0.0001,\n",
    "        \"momentum\": 0.9,\n",
    "        \"sched\": \"cosine\",\n",
    "        \"epochs\": 1000,\n",
    "        \"lr\": 1e-3,\n",
    "        \"batch_size\": 16,\n",
    "    }\n",
    "\n",
    "    # Log that training is starting\n",
    "    print(\"training\")\n",
    "\n",
    "    # Define the input dimensions for the model\n",
    "    input_dim = [3, 224, 224]\n",
    "\n",
    "    # Instantiate the data loader for training\n",
    "    dataloader = DataModule2(datapipe, num_workers=os.cpu_count())\n",
    "\n",
    "    # Instantiate the model and wrap it in a Lightning model\n",
    "    model = config.Model(input_dim=input_dim)\n",
    "    lit_model = config.LightningModel(model=model)\n",
    "\n",
    "    # Setup model checkpointing to save the best model\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        monitor=\"val/loss\",\n",
    "        filename=\"best\",\n",
    "        save_top_k=1,\n",
    "        mode=\"min\",\n",
    "        save_last=True,\n",
    "    )\n",
    "\n",
    "    # Setup Weights & Biases (Wandb) logger for tracking experiments\n",
    "    wandb = pl_loggers.WandbLogger(project=\"idr\", name=\"0093\", log_model=\"all\")\n",
    "\n",
    "    # Setup the trainer with distributed training strategy\n",
    "    trainer = config.Trainer(\n",
    "        accelerator=\"auto\",\n",
    "        devices=num_gpus_per_node,\n",
    "        num_nodes=num_nodes,\n",
    "        strategy=\"ddp\",  # Use Distributed Data Parallel (DDP) strategy\n",
    "        callbacks=[checkpoint],\n",
    "        logger=[wandb],\n",
    "    )\n",
    "\n",
    "    # Combine everything into a configuration object\n",
    "    cfg = config.Config(\n",
    "        dataloader=dataloader,\n",
    "        lit_model=lit_model,\n",
    "        trainer=trainer,\n",
    "        recipe=config.Recipe(**params),\n",
    "    )\n",
    "\n",
    "    # Instantiate the BioImageEmbed class and start training\n",
    "    bie = bioimage_embed.BioImageEmbed(cfg)\n",
    "    wandb.watch(bie.icfg.lit_model, log=\"all\")\n",
    "    bie.train()\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a403b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to submit the training job using SLURM\n",
    "def slurm(spec):\n",
    "    logdir = \"lightning_slurm/\"\n",
    "    os.makedirs(logdir, exist_ok=True)\n",
    "\n",
    "    # Submitit executor configuration\n",
    "    executor = submitit.AutoExecutor(folder=logdir)\n",
    "    executor.update_parameters(\n",
    "        mem_gb=2 * 32 * 4,  # 2GB per CPU, 32 CPUs per task, 4 tasks per node\n",
    "        timeout_min=1440 * 2,  # 48 hours\n",
    "        gpus_per_node=NUM_GPUS_PER_NODE,\n",
    "        tasks_per_node=1,\n",
    "        cpus_per_task=8,\n",
    "        nodes=NUM_NODES,\n",
    "        slurm_constraint=\"a100\",\n",
    "    )\n",
    "    job = executor.submit(train, spec, NUM_GPUS_PER_NODE, NUM_NODES)\n",
    "    print(job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878aba8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry point for running the training script directly\n",
    "if __name__ == \"__main__\":\n",
    "    # Use the FTP spec to train the model\n",
    "    spec = fsspec_ftp\n",
    "    # Start local training\n",
    "    train(spec)\n",
    "    # Alternatively, submit the job to SLURM\n",
    "    slurm(spec)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
